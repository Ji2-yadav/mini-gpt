{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yzPVIkpU4snQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xgfpTPAw5LLg"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "block_size = 64\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "dropout = 0.1\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "learning_rate = 1e-3\n",
        "input_data_path = 'data/input.txt'\n",
        "weights_path = 'weights/wt.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KN-X4Di4HlE",
        "outputId": "eb6d97e8-724d-4dc8-903b-4d871eab45f3"
      },
      "outputs": [],
      "source": [
        "#  Download Tiny Shakespeare Dataset\n",
        "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Cw8p0J5u4SNv"
      },
      "outputs": [],
      "source": [
        "with open(input_data_path, 'r') as f:\n",
        "    text = f.read()\n",
        "data = sorted(list(set(text)))\n",
        "\n",
        "vocab_size = len(data)      # all characters in data\n",
        "\n",
        "# tokenize and dekonize functions\n",
        "stoi = { d:i for i,d in enumerate(data)}\n",
        "itos = {i:d for i,d in enumerate(data)}\n",
        "\n",
        "def tokenize(token):\n",
        "    res = [stoi[t] for t in token]\n",
        "    return res\n",
        "\n",
        "def detokenize(token):\n",
        "    ll = [itos[t] for t in token]\n",
        "    res = ''.join(ll)\n",
        "    return res\n",
        "\n",
        "data = torch.tensor(tokenize(text))\n",
        "\n",
        "bp = int(0.9*len(data))\n",
        "\n",
        "# split the data\n",
        "train_data = data[:bp]\n",
        "val_data  = data[bp:]\n",
        "\n",
        "def get_batch(split):\n",
        "    split_type = train_data if split=='train' else val_data\n",
        "    idx = torch.randint(len(split_type) - block_size, (batch_size,))\n",
        "    x = torch.stack([split_type[i:i+block_size] for i in idx])\n",
        "    y = torch.stack([split_type[i+1:i+block_size+1] for i in idx])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y5_zUE7Y8F74"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_losses():\n",
        "    global model\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            model = model.to(device)\n",
        "            X = X.to(device)\n",
        "            Y = Y.to(device)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ECIJ7i8N5efr"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # self attention\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # B, T, C\n",
        "        q = self.query(x) # B, T, C\n",
        "        v = self.value(x) # B, T, C\n",
        "\n",
        "        # wei = torch.zeros(T,T)\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # B, T, T\n",
        "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        out = wei @ v # B, T, C\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_head)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([head(x) for head in self.heads], dim = -1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4* n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.attention = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.ln1(self.attention(x))\n",
        "        x = x + self.ln2(self.ffwd(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class miniLLM(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(vocab_size, n_embd)\n",
        "        self.pos_emb = nn.Embedding(vocab_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        token_emb = self.token_emb(idx) # B, T, C\n",
        "        pos_emb = self.pos_emb(torch.arange(T, device=device)) #T, C\n",
        "        x = token_emb + pos_emb # B, T, C\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x) # B, T, vocab_size\n",
        "        if(targets is None):\n",
        "            loss=None\n",
        "\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            logits = logits.view(B*T,C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_nums):\n",
        "        for _ in range(max_nums):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self.forward(idx_cond)\n",
        "            logits = logits[:,-1,:]\n",
        "            probs = F.softmax(logits,dim=-1)\n",
        "            pred = torch.multinomial(probs, num_samples = 1)\n",
        "            idx = torch.cat((idx, pred), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dlrudVHV5kaF",
        "outputId": "d83a1b40-06bc-48b8-e558-7afb5ed4c6df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = miniLLM(vocab_size)\n",
        "model = m.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ifKSa-t51_k",
        "outputId": "f02e9090-33bc-4962-e50c-c6a012d86447"
      },
      "outputs": [],
      "source": [
        "def training(save=False):\n",
        "    # training\n",
        "    for iter in range(max_iters):\n",
        "        # Print loss after each eval_interval\n",
        "        if iter%eval_interval==0 or iter==max_iters-1:\n",
        "            curr_loss = get_losses()\n",
        "            print(f\"Iter - {iter} : Train loss - {curr_loss['train']}, Val loss - {curr_loss['val']}\")\n",
        "\n",
        "        # Get batch\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        # Evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if save:\n",
        "            torch.save(model.state_dict(), weights_path)\n",
        "\n",
        "\n",
        "def inference():\n",
        "    model.eval()\n",
        "    context = torch.zeros((1,1), dtype = torch.long, device=device)\n",
        "    output = model.generate(context, max_nums=1000)\n",
        "    op = detokenize(output[0].tolist())\n",
        "    print(op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Not vastant:\n",
            "She sust me in the crown to finds,\n",
            "That she's vair the foe to formits find.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Upon my lord?\n",
            "\n",
            "LEONTES:\n",
            "With his note; coward is.\n",
            "\n",
            "PARIS:\n",
            "Why, go say made of bling.\n",
            "\n",
            "JULIET:\n",
            "'Twere it strength you the pendon of ruscored;\n",
            "And intent, smill not gruccibable,\n",
            "So be way more in my brother intent so much glad,\n",
            "The Volsces of he ew the humaglo, in the love in\n",
            "that is the title myself of fils, we did have done\n",
            "That is spulks and they plosture good man,\n",
            "I meaner accosman, and put my peined.\n",
            "\n",
            "ROMEO:\n",
            "By then, as Cangly azory,\n",
            "Sunswer the bandern their wife and they\n",
            "like upon my sword decrity for thyself,\n",
            "By thy face of this woit along.-\n",
            "Anight:\n",
            "Ye thou couding all as Romeo and trucking stoler,\n",
            "God king, and you Very of Woman:\n",
            "And by him lord it Caius.\n",
            "\n",
            "CATESBY:\n",
            "God they never to him. My fils!\n",
            "\n",
            "POMPEY:\n",
            "Rurse! Know I same thy lord, o wave the dangerous,\n",
            "Or's loss this light all thee.\n",
            "I have rack them; for when that is crest, and his\n",
            "much callames thine enpast live\n",
            "And to his y\n"
          ]
        }
      ],
      "source": [
        "inference()\n",
        "# training()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
